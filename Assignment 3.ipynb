{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 3: Non-Linear Models and Validation Metrics (37 total marks)\n",
    "### Due: October 24 at 11:59pm\n",
    "\n",
    "### Name: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses non-linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yellowbrick\n",
    "from yellowbrick import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2d2c3",
   "metadata": {},
   "source": [
    "## Part 1: Regression (14.5 marks)\n",
    "\n",
    "For this section, we will be continuing with the concrete example from yellowbrick. You will need to compare these results to the results from the previous assignment. Please use the results from the solution if you were unable to complete Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (0.5 marks)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the concrete dataset into the feature matrix `X` and target vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Import concrete dataset from yellowbrick library\n",
    "X, Y = yellowbrick.datasets.loaders.load_concrete(data_home=None, return_dataset=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0 marks)\n",
    "\n",
    "Data processing was completed in the previous assignment. No need to repeat here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import the Decision Tree, Random Forest and Gradient Boosting Machines regression models from sklearn\n",
    "2. Instantiate the three models with `max_depth = 5`. Are there any other parameters that you will need to set?\n",
    "3. Implement each machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the average training and validation accuracy using mean squared error with cross-validation. To do this, you will need to set `scoring='neg_mean_squared_error'` in your `cross_validate` function and negate the results (multiply by -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3f7a8",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: DT, RF and GB\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdc93a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Regressor      Scoring  TrainingAccuracy  \\\n",
      "0      Decision_Tree_Regressor  neg_mean_sq         47.918561   \n",
      "1      Random_Forest_Regressor  neg_mean_sq         31.804941   \n",
      "2  Gradient_Boosting_Regressor  neg_mean_sq          3.739270   \n",
      "\n",
      "   ValidationAccuracy  \n",
      "0          162.792015  \n",
      "1          162.193150  \n",
      "2           95.584348  \n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "regressors = {\n",
    "    'Decision_Tree_Regressor': {'Regressor': DecisionTreeRegressor(max_depth=5)},\n",
    "    'Random_Forest_Regressor': {'Regressor': RandomForestRegressor(max_depth=5)},\n",
    "    'Gradient_Boosting_Regressor': {'Regressor': GradientBoostingRegressor(max_depth=5)}\n",
    "}\n",
    "\n",
    "results = pd.DataFrame(columns=['Regressor', 'Scoring', 'TrainingAccuracy', 'ValidationAccuracy'])\n",
    "\n",
    "for regressorName, data in regressors.items():\n",
    "    regressor = data['Regressor']\n",
    "\n",
    "    # Fit the regressor\n",
    "    regressor.fit(X,Y)\n",
    "\n",
    "    crs_val = cross_validate(regressor, X, Y, scoring='neg_mean_squared_error', cv=5, return_train_score=True)\n",
    "\n",
    "    avg_train_mse = -crs_val['train_score'].mean()\n",
    "    avg_test_mse = -crs_val['test_score'].mean()\n",
    "\n",
    "    newRow = {\n",
    "        'Regressor': regressorName,\n",
    "        'Scoring': 'neg_mean_sq',\n",
    "        'TrainingAccuracy': avg_train_mse,\n",
    "        'ValidationAccuracy': avg_test_mse\n",
    "    }\n",
    "\n",
    "    results.loc[len(results)] = newRow\n",
    "\n",
    "print(results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31715a9d",
   "metadata": {},
   "source": [
    "Repeat the step above to print the R2 score instead of the mean-squared error. For this case, you can use `scoring='r2'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83539f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Regressor      Scoring  TrainingAccuracy  \\\n",
      "0      Decision_Tree_Regressor  neg_mean_sq         47.918561   \n",
      "1      Random_Forest_Regressor  neg_mean_sq         31.804941   \n",
      "2  Gradient_Boosting_Regressor  neg_mean_sq          3.739270   \n",
      "3      Decision_Tree_Regressor           r2          0.822887   \n",
      "4      Random_Forest_Regressor           r2          0.881743   \n",
      "5  Gradient_Boosting_Regressor           r2          0.986436   \n",
      "\n",
      "   ValidationAccuracy  \n",
      "0          162.792015  \n",
      "1          162.193150  \n",
      "2           95.584348  \n",
      "3            0.175363  \n",
      "4            0.176208  \n",
      "5            0.487536  \n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "for regressorName, data in regressors.items():\n",
    "    regressor = data['Regressor']\n",
    "\n",
    "    # Fit the regressor\n",
    "    regressor.fit(X,Y)\n",
    "\n",
    "    crs_val = cross_validate(regressor, X, Y, scoring='r2', cv=5, return_train_score=True)\n",
    "\n",
    "    avg_train_mse = crs_val['train_score'].mean()\n",
    "    avg_test_mse = crs_val['test_score'].mean()\n",
    "\n",
    "    newRow = {\n",
    "        'Regressor': regressorName,\n",
    "        'Scoring': 'r2',\n",
    "        'TrainingAccuracy': avg_train_mse,\n",
    "        'ValidationAccuracy': avg_test_mse\n",
    "    }\n",
    "\n",
    "    results.loc[len(results)] = newRow\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5257a98",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do these results compare to the results using a linear model in the previous assignment? Use values.\n",
    "\n",
    "While the regression models here all look to have lower mse than the linear regression, the values show some very serious signs of overfitting.  Example, Gradient Boosting Regressior, which is the most accurate of all the three regressors here, shows a mse training accuracy of 3.7, a tremendous value.  However the validation accuracy for the same thing is 95, more than an order of magnitude off.  Looking at last weeks assignment,  the mse for training and validation for the same value was 110 and 95.  Significantly more close, and even close enough to assume that overfitting wasnt expressly a part of the fit.  We can see the same effect taking place of overfitting,  seeing for r2 values for Gradient boosting being 0.98 for Trainign accuracy, and 0.48 for Validation Accuracy. Where in the linear model we have ~0.6 for both, meaning we were not overfit, and thus a representative model. \n",
    "\n",
    "1. Out of the models you tested, which model would you select for this dataset and why?\n",
    "\n",
    "I would like to look further into the Gradient_Boosting_Regressor, and see if the overfitting could be corrected,  this shows the most promise of a very accurate model, however not if it is completely over fit.  If this cannot be corrected, I would then revert back to the Linear Model.  While it isnt as accurate, it also wont produce seemingly incorrect results. \n",
    "\n",
    "1. If you wanted to increase the accuracy of the tree-based models, what would you do? Provide two suggestions.\n",
    "\n",
    "Some things to better help the overfitting, would be things like data pruning, or some regularization.  If all else fails, back to the linear regression. \n",
    "\n",
    "*ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "\n",
    "Most of the code I followed the same format that I utilized in lab 2,  in terms of the loops to process everything.  Some of the information for syntax I had to look up in the library documentation, and some I had to look up from fathful ol' GPT. \n",
    "\n",
    "1. In what order did you complete the steps?\n",
    "\n",
    "In the same order they were listed...like a sane human would.  In this case there wouldnt really have been much option to do it otherwise.  \n",
    "\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "\n",
    "I asked it for some syntax for the tree based commands,  specifically the cross_validation.  While these things are generally not that complicated in how they function, there is a million different syntax's and if you tried to guess it, youd be here all day.  Especially since the intillisence in ipynb files is mega slow. \n",
    "\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?\n",
    "\n",
    "Just understanding syntax and the definitions for some of the attributies.  However just a quick google away.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 2: Classification (17.5 marks)\n",
    "\n",
    "You have been asked to develop code that can help the user classify different wine samples. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (2 marks)\n",
    "\n",
    "The data used for this task can be downloaded from UCI: https://archive.ics.uci.edu/dataset/109/wine\n",
    "\n",
    "Use the pandas library to load the dataset. You must define the column headers if they are not included in the dataset \n",
    "\n",
    "You will need to split the dataset into feature matrix `X` and target vector `y`. Which column represents the target vector?\n",
    "\n",
    "Print the size and type of `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X size: (178, 13)\n",
      "y size: (178,)\n",
      "X type: <class 'pandas.core.frame.DataFrame'>\n",
      "y type: <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import wine dataset\n",
    "\n",
    "headers = ['Class','Alcohol', 'Malic Acid','Ash','Alcalinity of Ash','Magnesium','Total Phenols','Flavanoids','Nonflavanoid Phenols','Proanthocyanins','Color Intensity','Hue','OD280/OD315 of Diluted Wines','Proline']\n",
    "\n",
    "data = pd.read_csv('wine.data', header=None, names=headers)\n",
    "\n",
    "y = data['Class']\n",
    "X = data.drop('Class',axis=1)\n",
    "\n",
    "print(\"X size:\", X.shape)\n",
    "print(\"y size:\", y.shape)\n",
    "print(\"X type:\", type(X))\n",
    "print(\"y type:\", type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28af110",
   "metadata": {},
   "source": [
    "Print the first five rows of the dataset to inspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea266921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic Acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of Ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total Phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid Phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color Intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of Diluted Wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Alcohol  Malic Acid   Ash  Alcalinity of Ash  Magnesium  \\\n",
       "0      1    14.23        1.71  2.43               15.6        127   \n",
       "1      1    13.20        1.78  2.14               11.2        100   \n",
       "2      1    13.16        2.36  2.67               18.6        101   \n",
       "3      1    14.37        1.95  2.50               16.8        113   \n",
       "4      1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total Phenols  Flavanoids  Nonflavanoid Phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color Intensity   Hue  OD280/OD315 of Diluted Wines  Proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834fc8fe",
   "metadata": {},
   "source": [
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97c6e9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "missing_values = data.isnull().sum().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070956af",
   "metadata": {},
   "source": [
    "How many samples do we have of each type of wine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b37a6fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "2    71\n",
       "1    59\n",
       "3    48\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "\n",
    "wine_counts = data['Class'].value_counts()\n",
    "\n",
    "wine_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `SVC` and `DecisionTreeClassifier` from sklearn\n",
    "2. Instantiate models as `SVC()` and `DecisionTreeClassifier(max_depth = 3)`\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870b0d2",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model \n",
    "\n",
    "Calculate the average training and validation accuracy using `cross_validate` for the two different models listed in Step 3. For this case, use `scoring='accuracy'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bbd83",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "#### Step 5.1: Compare Models\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Classifier  TrainingAccuracy  ValidationAccuracy\n",
      "0           SVC          0.703743            0.663492\n",
      "1  DecisionTree          0.974756            0.876508\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "svc_model = SVC()\n",
    "dt_model = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "classifiers = {\n",
    "    'SVC': {'Classifier': cross_validate(svc_model, X, y, cv=5, scoring='accuracy', return_train_score=True)},\n",
    "    'DecisionTree': {'Classifier': cross_validate(dt_model, X, y, cv=5, scoring='accuracy', return_train_score=True)}\n",
    "}\n",
    "\n",
    "results2 = pd.DataFrame(columns=['Classifier', 'TrainingAccuracy', 'ValidationAccuracy'])\n",
    "\n",
    "for classifierName, data in classifiers.items():\n",
    "    classifier = data['Classifier']\n",
    "\n",
    "    train_score = classifier['train_score'].mean()\n",
    "    test_score = classifier['test_score'].mean()\n",
    "\n",
    "    newRow = {\n",
    "        'Classifier': classifierName,\n",
    "        'TrainingAccuracy': train_score,\n",
    "        'ValidationAccuracy': test_score\n",
    "    }\n",
    "\n",
    "    results2.loc[len(results2)] = newRow\n",
    "\n",
    "\n",
    "print(results2)\n",
    "\n",
    "\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e17878",
   "metadata": {},
   "source": [
    "#### Step 5.2: Visualize Classification Errors\n",
    "Which method gave the highest accuracy? Use this method to print the confusion matrix and classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44b091a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Implement best model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "dt_model = DecisionTreeClassifier(max_depth=3)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dt_model.predict(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09d21b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: Print confusion matrix using a heatmap\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 1', 'Class 2', 'Class 3'], yticklabels=['Class 1', 'Class 2', 'Class 3'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ef95947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      1.00      0.97        14\n",
      "           2       1.00      0.94      0.97        16\n",
      "           3       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.98      0.98        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Print classification report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf319621",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do the training and validation accuracy change depending on the method used? Explain with values.\n",
    "\n",
    "We saw that the decision tree model had better results, 97% training, and 87% validation.  This may squew slightly towards a small overfit, however I dont think that it is entirely outside the realms of normality.  If we were doing a bigger model, I would put some more time into refining to get the model to a better fit, however I feel like this is representative at this point.  The SVC was slightly lower accuracy at 70 and 66% respectively.  A more consistent model, however not as accurate as the decision tree.  \n",
    "\n",
    "1. What are two reasons why the support vector machines model did not work as well as the tree-based model?\n",
    "\n",
    "Something like this context,  wine,  is largely based on features of the wine itself.  Such when you have a feature based model, soemthing like a decision tree is a perfect model.  SVC has the ability to model non-linearities, however must be done so with some kernel tricks, and it wasnt really what this mdoel was built for.  \n",
    "\n",
    "1. How many samples were incorrectly classified in step 5.2? \n",
    "\n",
    "Only 1!\n",
    "\n",
    "1. In this case, is maximizing precision or recall more important? Why?\n",
    "\n",
    "I think here, precision is more important,  as we are trying to directly classify many different wines and specify them with their correct class.  If we were only trying to identify one aspect or one class in particular, than recall would be more important, however in this case I see this being used as a winemakers tool, to help determine if their wine is to spec with their brand's reputation etc, and if it isnt, then...make some different wine haha.  \n",
    "\n",
    "*YOUR ANSWERS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ff8ae",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "\n",
    "Code came from all over the place,  some lecture slides,  soem of teh library documentation, soem youtube, and some GPT. \n",
    "\n",
    "1. In what order did you complete the steps?\n",
    "\n",
    "Top to bottom,  no other way in this case. \n",
    "\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "\n",
    "My use of generative AI is largely a time saving thing to not have to read through pages and pages of documentation to understand the syntax,  so my prompts will be somethign along the lines of \"I want to make this decision tree with a max of 3 levels in it for this application,  where do I start?\"\n",
    "\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?\n",
    "\n",
    "I would like to get better at being able to know more of this stuff off hand.  I understand the mdoels and what they are doing, however just getting a more consistent grasp of the syntax to be able to do this without as much \"aid\" would be lovely.  However, like all programming I believe this is just a time and practice thing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e837da",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd7358d",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "*ADD YOUR FINDINGS HERE*\n",
    "\n",
    "I am seeing more and more, that the different applications have very different optimum models.  You can have a model that works fantastic for something in one context,  say normal distribution of student height,  or a linear regression model for trees growth vs temperature or latitude, and you can get a 95% model here.  But no doubt that the same linear regression model would work like hot garbage when taken to this wine example, and vice versa.  The code and the context of this class is not inherently difficult,  its straight forward, and the mathematic models are fairly easy to grasp.  I think it is really just the practice of understanding what types of data sets will be best represented by which model.  YOu can take an iterative approach to this, however I do also believe that this is something that might also come with expereince, after seeing gazillions of data sets,  one might be able to better predict what model is going to perform the best in the respective context. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "I liked this assignment as it gives some more examples of some more applications, and different models that can be used.  I like the format of these assignments, as it is real data, for real applications,  nto just the same silly programmign questions over and over again, I feel like I really do grasp teh concept and learn better in this format.   I also like being familiarized with more models, and their use cases.  I am also a big wine snob,  so i particularly enjoyed part 2 of this assignment.  \n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21e53b",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (3 marks)\n",
    "\n",
    "Repeat Part 2 and compare the support vector machines model used to `LinearSVC(max_iter=5000)`. Does using `LinearSVC` improve the results? Why or why not?\n",
    "\n",
    "Is `LinearSVC` a good fit for this dataset? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30fea72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc68a4",
   "metadata": {},
   "source": [
    "*ANSWER HERE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241c3b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
